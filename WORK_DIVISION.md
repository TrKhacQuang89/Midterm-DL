# Káº¿ Hoáº¡ch PhÃ¢n Chia CÃ´ng Viá»‡c Chi Tiáº¿t - Project MLP NumPy

Dá»±a trÃªn cáº¥u trÃºc file `mlp_network.py`, cÃ¡c pháº§n kiáº¿n thá»©c vÃ  mÃ£ nguá»“n Ä‘Æ°á»£c chia cá»¥ thá»ƒ cho 3 thÃ nh viÃªn nhÆ° sau:

---

## ğŸ‘¤ ThÃ nh ViÃªn 1: Dá»¯ Liá»‡u & Háº¡ Táº§ng (Data & Infrastructure)
*NgÆ°á»i nÃ y chá»‹u trÃ¡ch nhiá»‡m chuáº©n bá»‹ "nguyÃªn liá»‡u" vÃ  hiá»ƒn thá»‹ káº¿t quáº£.*

**CÃ¡c pháº§n phá»¥ trÃ¡ch trong code:**
- **Dataset Loading:** HÃ m `load_dataset()`.
- **Model Storage:** CÃ¡c hÃ m `save_model()` vÃ  `load_model()`.
- **Visualization:** HÃ m `draw_loss()` vÃ  cÃ¡c thÆ° viá»‡n `matplotlib`, `pandas`.

**Ná»™i dung cáº§n tÃ¬m hiá»ƒu:**
- CÃ¡ch Ä‘á»c áº£nh tá»« thÆ° má»¥c, resize áº£nh vÃ  chuáº©n hÃ³a pixel báº±ng thÆ° viá»‡n **PIL**.
- CÃ¡ch lÆ°u trá»¯ vÃ  táº£i trá»ng sá»‘ mÃ´ hÃ¬nh sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng `.npz` cá»§a **NumPy**.
- CÃ¡ch váº½ biá»ƒu Ä‘á»“ loss vÃ  accuracy Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh huáº¥n luyá»‡n.

---

## ğŸ‘¤ ThÃ nh ViÃªn 2: Kiáº¿n TrÃºc & Lan Truyá»n Tiáº¿n (Architecture & Forward)
*NgÆ°á»i nÃ y thiáº¿t káº¿ "nÃ£o bá»™" cá»§a AI vÃ  quy Ä‘á»‹nh cÃ¡ch nÃ³ suy nghÄ©.*

**CÃ¡c pháº§n phá»¥ trÃ¡ch trong code:**
- **Model Initialization:** HÃ m `initialize_model()`.
- **Activation Functions:** CÃ¡c hÃ m `relu()` vÃ  `softmax()`.
- **Forward Pass:** HÃ m `forward()`.
- **Loss Function:** HÃ m `cross_entropy_loss()`.

**Ná»™i dung cáº§n tÃ¬m hiá»ƒu:**
- CÃ¡ch khá»Ÿi táº¡o ma tráº­n trá»ng sá»‘ (Weights) vÃ  Ä‘á»™ lá»‡ch (Bias) (He Initialization).
- CÆ¡ cháº¿ cá»§a hÃ m **ReLU** (lá»c tÃ­n hiá»‡u) vÃ  **Softmax** (tÃ­nh xÃ¡c suáº¥t lá»›p).
- PhÃ©p nhÃ¢n ma tráº­n giá»¯a dá»¯ liá»‡u vÃ  trá»ng sá»‘ (`np.dot`).
- CÃ´ng thá»©c tÃ­nh Ä‘á»™ lá»—i Cross-Entropy giá»¯a dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿.

---

## ğŸ‘¤ ThÃ nh ViÃªn 3: ToÃ¡n Há»c & Tá»‘i Æ¯u HÃ³a (Math & Optimization)
*NgÆ°á»i nÃ y chá»‹u trÃ¡ch nhiá»‡m cho cÆ¡ cháº¿ "há»c táº­p" cá»§a AI thÃ´ng qua Ä‘áº¡o hÃ m.*

**CÃ¡c pháº§n phá»¥ trÃ¡ch trong code:**
- **Backward Pass (Quan trá»ng nháº¥t):** HÃ m `backward()`.
- **Derivatives:** HÃ m `relu_derivative()`.
- **Parameter Update:** HÃ m `update_parameters()`.
- **Execution Loop:** CÃ¡c hÃ m `train()` vÃ  `test()`.

**Ná»™i dung cáº§n tÃ¬m hiá»ƒu:**
- Thuáº­t toÃ¡n **Backpropagation** (Lan truyá»n ngÆ°á»£c) Ä‘á»ƒ tÃ­nh lá»—i cho tá»«ng lá»›p.
- CÃ¡ch tÃ­nh Ä‘áº¡o hÃ m cá»§a hÃ m ReLU vÃ  Softmax.
- Thuáº­t toÃ¡n **Stochastic Gradient Descent (SGD)** Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘.
- CÃ¡ch Ä‘iá»u chá»‰nh **Learning Rate** Ä‘á»ƒ mÃ´ hÃ¬nh há»™i tá»¥ tá»‘t nháº¥t.

---

## ğŸ“ˆ Quy TrÃ¬nh Phá»‘i Há»£p
1. **ThÃ nh viÃªn 1** cung cáº¥p danh sÃ¡ch áº£nh (`data.append`) cho **ThÃ nh viÃªn 3**.
2. **ThÃ nh viÃªn 2** cung cáº¥p cáº¥u trÃºc máº¡ng (`model`) cho **ThÃ nh viÃªn 3**.
3. **ThÃ nh viÃªn 3** Ä‘iá»u khiá»ƒn vÃ²ng láº·p huáº¥n luyá»‡n, sau Ä‘Ã³ chuyá»ƒn káº¿t quáº£ cho **ThÃ nh viÃªn 1** váº½ biá»ƒu Ä‘á»“.

