# TÃ€I LIá»†U THUYáº¾T TRÃŒNH NHÃ“M: Dá»° ÃN AI PHÃ‚N LOáº I LINH KIá»†N ÄIá»†N Tá»¬ (MLP NUMPY)

TÃ i liá»‡u nÃ y Ä‘Æ°á»£c biÃªn soáº¡n Ä‘á»ƒ Ä‘áº£m báº£o ná»™i dung thuyáº¿t trÃ¬nh cá»§a 3 thÃ nh viÃªn liá»n máº¡ch, logic vÃ  chuyÃªn nghiá»‡p.

---

## ğŸ“… Cáº¤U TRÃšC BÃ€I THUYáº¾T TRÃŒNH (3 PHáº¦N - 1 CÃ‚U CHUYá»†N)

### ğŸ¤ PHáº¦N 1: Dá»® LIá»†U & CÆ  Sá» Háº  Táº¦NG (THÃ€NH VIÃŠN 1)
*Má»¥c tiÃªu: Äáº·t váº¥n Ä‘á» vÃ  giá»›i thiá»‡u "nguyÃªn liá»‡u" Ä‘áº§u vÃ o.*

**1. Má»Ÿ Ä‘áº§u & Äáº·t váº¥n Ä‘á»:**
- Giá»›i thiá»‡u má»¥c tiÃªu dá»± Ã¡n: Táº¡o ra má»™t há»‡ thá»‘ng tá»± Ä‘á»™ng nháº­n diá»‡n 10 loáº¡i linh kiá»‡n Ä‘iá»‡n tá»­ (Battery, Capacitor, Resistor, etc.) tá»« hÃ¬nh áº£nh.
- Táº¡i sao dÃ¹ng NumPy? Äá»ƒ hiá»ƒu sÃ¢u báº£n cháº¥t toÃ¡n há»c cá»§a Deep Learning mÃ  khÃ´ng phá»¥ thuá»™c vÃ o cÃ¡c thÆ° viá»‡n Ä‘en (black-box) nhÆ° PyTorch/TensorFlow.

**2. Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u (The Kitchen):**
- **Thu tháº­p:** Dá»¯ liá»‡u Ä‘Æ°á»£c tá»• chá»©c theo thÆ° má»¥c (Class-based structure).
- **Tiá»n xá»­ lÃ½ (`load_dataset`):** 
    - Chuyá»ƒn áº£nh sang thang Ä‘á»™ xÃ¡m (`L`) Ä‘á»ƒ giáº£m khá»‘i lÆ°á»£ng tÃ­nh toÃ¡n.
    - Resize vá» 64x64 pixel (tá»•ng 4096 Ä‘áº§u vÃ o).
    - Chuáº©n hÃ³a (Normalization) vá» khoáº£ng [0, 1] báº±ng cÃ¡ch chia cho 255.0.

**3. Minh há»a trá»±c quan (Technical Preview - ÄÃ£ tÃ­ch há»£p trong Demo):**
- **áº¢nh tiá»n xá»­ lÃ½:** Show cho khÃ¡n giáº£ tháº¥y sá»± khÃ¡c biá»‡t giá»¯a áº£nh gá»‘c vÃ  áº£nh 64x64 (má» hÆ¡n, grayscale) - Ä‘Ã¢y lÃ  nhá»¯ng gÃ¬ AI thá»±c sá»± nhÃ¬n tháº¥y.
- **VectÆ¡ sá»‘ (Vectorization):** Chuyá»ƒn Ä‘á»•i tá»« áº£nh sang má»™t máº£ng NumPy chá»©a 4096 con sá»‘. Giáº£i thÃ­ch ráº±ng mÃ¡y tÃ­nh khÃ´ng hiá»ƒu "hÃ¬nh áº£nh", nÃ³ chá»‰ hiá»ƒu cÃ¡c giÃ¡ trá»‹ cÆ°á»ng Ä‘á»™ sÃ¡ng tá»« 0 Ä‘áº¿n 1.

**4. CÃ´ng cá»¥ trá»±c quan & á»¨ng dá»¥ng (`streamlit_app.py`):**
- Giá»›i thiá»‡u giao diá»‡n web demo Ä‘Ã£ xÃ¢y dá»±ng: Upload áº£nh -> Inference -> Hiá»‡n káº¿t quáº£ & XÃ¡c suáº¥t (Confidence).
- *Thá»±c hiá»‡n Demo trá»±c tiáº¿p:* Táº£i má»™t áº£nh lÃªn vÃ  chá»‰ vÃ o pháº§n **"Technical: Preprocessing & Vectorization"** Ä‘á»ƒ giáº£i thÃ­ch cho khÃ¡n giáº£.
- *Lá»i dáº«n chuyá»ƒn giao:* "Sau khi Ä‘Ã£ cÃ³ nguyÃªn liá»‡u sáº¡ch, chÃºng ta cáº§n má»™t bá»™ nÃ£o Ä‘á»ƒ xá»­ lÃ½ chÃºng. Sau Ä‘Ã¢y, báº¡n [TÃªn ThÃ nh viÃªn 2] sáº½ giá»›i thiá»‡u vá» kiáº¿n trÃºc bá»™ nÃ£o nÃ y."

---

### ğŸ¤ PHáº¦N 2: KIáº¾N TRÃšC MÃ” HÃŒNH & LUá»’NG TÆ¯ DUY (THÃ€NH VIÃŠN 2)
*Má»¥c tiÃªu: Giáº£i thÃ­ch cáº¥u trÃºc "bá»™ nÃ£o" vÃ  cÃ¡ch nÃ³ Ä‘Æ°a ra dá»± Ä‘oÃ¡n.*

**1. Cáº¥u trÃºc máº¡ng NÆ¡-ron (The Brain Architecture):**
- Giá»›i thiá»‡u mÃ´ hÃ¬nh MLP 6 táº§ng (5 táº§ng áº©n): 4096 (Input) -> 4096 -> 2048 -> 1024 -> 512 -> 256 -> 10 (Output).
- **Khá»Ÿi táº¡o (`initialize_model`):** Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p **He Initialization** Ä‘á»ƒ cÃ¡c trá»ng sá»‘ khÃ´ng quÃ¡ lá»›n cÅ©ng khÃ´ng quÃ¡ nhá», giÃºp máº¡ng dá»… há»c hÆ¡n.

**2. Luá»“ng suy luáº­n (`forward`):**
- Giáº£i thÃ­ch phÃ©p toÃ¡n cá»‘t lÃµi: `Y = X.W + b` (Dá»¯ liá»‡u nhÃ¢n Trá»ng sá»‘ cá»™ng Äá»™ lá»‡ch).
- **HÃ m kÃ­ch hoáº¡t (Filter):**
    - `ReLU`: ÄÃ³ng vai trÃ² bá»™ lá»c thÃ´ng tin, loáº¡i bá» cÃ¡c giÃ¡ trá»‹ Ã¢m (khÃ´ng quan trá»ng) Ä‘á»ƒ giá»¯ láº¡i Ä‘áº·c trÆ°ng ná»•i báº­t.
    - `Softmax` (táº¡i táº§ng cuá»‘i): Biáº¿n káº¿t quáº£ thÃ´ thÃ nh pháº§n trÄƒm xÃ¡c suáº¥t (vÃ­ dá»¥: 90% lÃ  Resistor).

**3. Äo lÆ°á»ng sai sá»‘ (`cross_entropy`):**
- CÃ¡ch mÃ´ hÃ¬nh tá»± Ä‘Ã¡nh giÃ¡: So sÃ¡nh dá»± Ä‘oÃ¡n vá»›i nhÃ£n tháº­t. "HÃ¬nh pháº¡t" cÃ ng cao náº¿u mÃ´ hÃ¬nh cÃ ng tá»± tin vÃ o Ä‘Ã¡p Ã¡n sai.
- *Lá»i dáº«n chuyá»ƒn giao:* "NhÆ°ng lÃ m tháº¿ nÃ o Ä‘á»ƒ mÃ´ hÃ¬nh biáº¿t mÃ¬nh sai á»Ÿ Ä‘Ã¢u vÃ  tá»± sá»­a? ÄÃ¢y chÃ­nh lÃ  pháº§n tinh tÃºy nháº¥t do báº¡n [TÃªn ThÃ nh viÃªn 3] trÃ¬nh bÃ y."

---

### ğŸ¤ PHáº¦N 3: CÆ  CHáº¾ Há»ŒC Táº¬P & Tá»I Æ¯U HÃ“A (THÃ€NH VIÃŠN 3)
*Má»¥c tiÃªu: Giáº£i thÃ­ch cÃ¡ch AI "rÃºt kinh nghiá»‡m" vÃ  káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c.*

**1. Lan truyá»n ngÆ°á»£c - TÃ¬m lá»—i (`backward`):**
- ÄÃ¢y lÃ  bÆ°á»›c "Há»“i tÆ°á»Ÿng": Äi ngÆ°á»£c tá»« káº¿t quáº£ sai vá» tá»«ng lá»›p phÃ­a trÆ°á»›c.
- Sá»­ dá»¥ng Ä‘áº¡o hÃ m (`relu_derivative`) Ä‘á»ƒ tÃ­nh xem má»—i sá»£i dÃ¢y tháº§n kinh (W) Ä‘Ã£ Ä‘Ã³ng gÃ³p bao nhiÃªu pháº§n vÃ o cÃ¡i sai Ä‘Ã³.

**2. Cáº­p nháº­t thÃ´ng minh (`update_parameters`):**
- Thuáº­t toÃ¡n Gradient Descent: Äiá»u chá»‰nh nháº¹ cÃ¡c trá»ng sá»‘ theo hÆ°á»›ng giáº£m lá»—i.
- **Learning Rate:** Giáº£i thÃ­ch táº§m quan trá»ng cá»§a viá»‡c "há»c tá»« tá»«" Ä‘á»ƒ khÃ´ng bá» lá»¡ Ä‘iá»ƒm tá»‘i Æ°u.

**3. Huáº¥n luyá»‡n & Káº¿t quáº£ (`train`, `test`):**
- Quy trÃ¬nh `Epoch`: Cho mÃ´ hÃ¬nh xem Ä‘i xem láº¡i dá»¯ liá»‡u (30 vÃ²ng) Ä‘á»ƒ tháº©m tháº¥u kiáº¿n thá»©c.
- **Shuffle:** XÃ¡o trá»™n áº£nh Ä‘á»ƒ mÃ´ hÃ¬nh khÃ´ng "há»c váº¹t" thá»© tá»±.
- **TrÃ¬nh diá»…n káº¿t quáº£:** Show biá»ƒu Ä‘á»“ loss (giáº£m dáº§n qua thá»i gian) vÃ  Ä‘á»™ chÃ­nh xÃ¡c (Accuracy) cuá»‘i cÃ¹ng trÃªn táº­p Test.

**4. Káº¿t luáº­n:**
- TÃ³m táº¯t: Dá»± Ã¡n Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng bá»™ phÃ¢n loáº¡i linh kiá»‡n tá»« con sá»‘ 0 vá»›i NumPy.
- HÆ°á»›ng phÃ¡t triá»ƒn: Thá»­ nghiá»‡m vá»›i CNN (Máº¡ng nÆ¡-ron tÃ­ch cháº­p) hoáº·c tÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘á»ƒ chÃ­nh xÃ¡c hÆ¡n.

---

## ğŸ’¡ Máº¸O Äá»‚ LIá»€N Máº CH TRONG BUá»”I DIá»„N
- **Sá»­ dá»¥ng tá»« ná»‘i:** "Tiáº¿p ná»‘i pháº§n dá»¯ liá»‡u cá»§a...", "NhÆ° ThÃ nh viÃªn 1 Ä‘Ã£ nÃ³i...", "Äá»ƒ cá»¥ thá»ƒ hÃ³a kiáº¿n trÃºc mÃ  ThÃ nh viÃªn 2 vá»«a nÃªu...".
- **Ãnh máº¯t:** ThÃ nh viÃªn vá»«a káº¿t thÃºc nÃªn nhÃ¬n vá» phÃ­a thÃ nh viÃªn sáº¯p báº¯t Ä‘áº§u Ä‘á»ƒ dáº«n dáº¯t sá»± chÃº Ã½ cá»§a khÃ¡n giáº£.
- **Thá»‘ng nháº¥t thuáº­t ngá»¯:** Cáº£ nhÃ³m dÃ¹ng chung tá»« "Trá»ng sá»‘" (Weights), "Táº§ng áº©n" (Hidden layers), "Äá»™ lá»—i" (Loss).

---
*TÃ i liá»‡u Ä‘Æ°á»£c soáº¡n tháº£o tá»± Ä‘á»™ng bá»Ÿi Antigravity AI há»— trá»£ nhÃ³m cá»§a báº¡n.*
